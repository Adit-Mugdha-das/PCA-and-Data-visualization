# Principal Component Analysis (PCA) and Data Visualization 

This assignment implements **Principal Component Analysis (PCA)** for dimensionality reduction and effective data visualization.  
It is part of **Week 2 (Course 3: Unsupervised Learning, Recommenders, Reinforcement Learning)** from the **Machine Learning Specialization** by **Andrew Ng** on Coursera.

##  Description

In this lab, I applied PCA to project high-dimensional data onto a lower-dimensional subspace while preserving as much variance as possible. The reduced representations were then used for visualization and compression tasks.

### Key Concepts Covered:
- Principal Component Analysis (PCA)
- Covariance matrix computation
- Eigenvector and eigenvalue decomposition (via SVD)
- Dimensionality reduction and feature compression
- Data reconstruction from reduced features
- Visualization of high-dimensional datasets in 2D/3D

##  Files Included

- `pca_lab.ipynb`: Jupyter notebook with PCA implementation and visualizations
- `lab_utils_pca.py`: Utility functions for plotting and data normalization
- `data/`: Contains datasets for PCA application (face images, 2D points)

> ⚠️ This repository contains only my original work and adheres to Coursera's Honor Code.

##  Tools Used

- Python 3
- NumPy
- Matplotlib
- SciPy (for SVD)
- Jupyter Notebook

##  Course Info

This assignment is part of:
> [Machine Learning Specialization](https://www.coursera.org/specializations/machine-learning-introduction)  
> Instructor: **Andrew Ng**  
> Course 3: Unsupervised Learning, Recommenders, Reinforcement Learning  
> Week 2: Principal Component Analysis and Data Visualization

##  License

This repository is intended for educational and portfolio purposes only. Please do not use it for direct submission on Coursera.

---

 Star the repo if you're excited about machine learning and data visualization!
